{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDp0HmnmCat72jMbV0Lb3X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuhash-cell/GeoBike-Station-Planner/blob/main/Bike_stations_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Source\n",
        "The dataset was obtained from Capital Bikeshare's System Data. It includes detailed trip records, such as start and end times, trip durations, and rider demographics, providing a comprehensive view of bike usage in the Washington, D.C. area."
      ],
      "metadata": {
        "id": "-hiPYsooboNq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Pg3aAvlbm0H",
        "outputId": "f89bc355-91ed-4527-cd88-bebdbcb701fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "August DataFrame: (614639, 13)\n",
            "September DataFrame: (720309, 13)\n",
            "October DataFrame: (725346, 13)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV files into separate DataFrames\n",
        "df_aug = pd.read_csv('/content/202408-capitalbikeshare-tripdata.csv')\n",
        "df_sep = pd.read_csv('/content/202409-capitalbikeshare-tripdata.csv')\n",
        "df_oct = pd.read_csv('/content/202410-capitalbikeshare-tripdata.csv')\n",
        "\n",
        "# Display the shapes of the DataFrames\n",
        "print(f\"August DataFrame: {df_aug.shape}\")\n",
        "print(f\"September DataFrame: {df_sep.shape}\")\n",
        "print(f\"October DataFrame: {df_oct.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The dataset was loaded into a pandas DataFrame from a CSV file using the specified file path. This prepares the data for analysis, enabling efficient manipulation and exploration."
      ],
      "metadata": {
        "id": "h3RYxduqck7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the three DataFrames into one\n",
        "df = pd.concat([df_aug, df_sep, df_oct], ignore_index=True)"
      ],
      "metadata": {
        "id": "GRA1-RVQk61m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter out rows where start_station_name or end_station_name is missing\n"
      ],
      "metadata": {
        "id": "hf51K2YOlMpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_stations = df[['start_station_name', 'start_lat', 'start_lng']].dropna()\n",
        "end_stations = df[['end_station_name', 'end_lat', 'end_lng']].dropna()"
      ],
      "metadata": {
        "id": "QITzsaNjk9RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rename columns to make them consistent for combining"
      ],
      "metadata": {
        "id": "UPBGtAeMlUci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_stations.rename(columns={'start_station_name': 'station_name',\n",
        "                               'start_lat': 'latitude',\n",
        "                               'start_lng': 'longitude'}, inplace=True)\n",
        "\n",
        "end_stations.rename(columns={'end_station_name': 'station_name',\n",
        "                             'end_lat': 'latitude',\n",
        "                             'end_lng': 'longitude'}, inplace=True)"
      ],
      "metadata": {
        "id": "eRZiNGVSlVML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concatenate start and end stations"
      ],
      "metadata": {
        "id": "6emBhu7vluip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_stations = pd.concat([start_stations, end_stations])"
      ],
      "metadata": {
        "id": "mSYRU8fulvRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop duplicates to keep unique station names with coordinates\n"
      ],
      "metadata": {
        "id": "NkzGaxf3l1J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Existing_stations = all_stations.drop_duplicates(subset=['station_name']).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "9qUivDU3l2C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the stations to a CSV file"
      ],
      "metadata": {
        "id": "TbrzgGQGl5QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path = '/content/Existing_stations.csv'\n",
        "Existing_stations.to_csv(output_file_path, index=False)"
      ],
      "metadata": {
        "id": "bf404l4bl736"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import libraries"
      ],
      "metadata": {
        "id": "L-S7MkD0mtcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "import osmnx as ox\n",
        "import networkx as nx\n",
        "from geopy.distance import geodesic"
      ],
      "metadata": {
        "id": "ecpm88xHm_ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract coordinates (start and end points)"
      ],
      "metadata": {
        "id": "knKcdeYanGs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates = pd.concat([\n",
        "    df[['start_lat', 'start_lng']].rename(columns={'start_lat': 'latitude', 'start_lng': 'longitude'}),\n",
        "    df[['end_lat', 'end_lng']].rename(columns={'end_lat': 'latitude', 'end_lng': 'longitude'})\n",
        "]).dropna()\n",
        "print(f\"Loaded {len(coordinates)} coordinates.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ICr2OtLnKAm",
        "outputId": "10c9db58-05f9-414e-f527-d196c4728bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 4119196 coordinates.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the place and download the simplified road network"
      ],
      "metadata": {
        "id": "QC3ex0_anZNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "place_name = \"Washington, D.C., USA\"\n",
        "G = ox.graph_from_place(place_name, network_type=\"bike\", simplify=True, retain_all=False)"
      ],
      "metadata": {
        "id": "JmlJhNbcnjQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract nodes with x (longitude) and y (latitude) coordinates\n"
      ],
      "metadata": {
        "id": "STheIhw0odjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = ox.graph_to_gdfs(G, nodes=True, edges=False)\n",
        "nodes_df = nodes[['x', 'y']].reset_index()"
      ],
      "metadata": {
        "id": "uyKdHTmeoeiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a GeoDataFrame for road network nodes"
      ],
      "metadata": {
        "id": "9YBmBlDXohri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nodes_gdf = gpd.GeoDataFrame(nodes_df, geometry=gpd.points_from_xy(nodes_df['x'], nodes_df['y']), crs=\"EPSG:4326\")"
      ],
      "metadata": {
        "id": "4ivGZqxzolcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a geofence using the convex hull of the road network nodes"
      ],
      "metadata": {
        "id": "WzJNpCEzop0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "geofence_polygon = nodes_gdf.unary_union.convex_hull"
      ],
      "metadata": {
        "id": "iFCSUs95oqQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the coordinates DataFrame to a GeoDataFrame"
      ],
      "metadata": {
        "id": "Riomv81oo05S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates_gdf = gpd.GeoDataFrame(\n",
        "    coordinates,\n",
        "    geometry=gpd.points_from_xy(coordinates['longitude'], coordinates['latitude']),\n",
        "    crs=\"EPSG:4326\"\n",
        ")"
      ],
      "metadata": {
        "id": "2orrfhg1o3tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter the coordinates that fall within the geofence polygon"
      ],
      "metadata": {
        "id": "38nVxKq0o7bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_coordinates = coordinates_gdf[coordinates_gdf.within(geofence_polygon)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "8VJqvIkMo_o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the existing stations DataFrame to a GeoDataFrame"
      ],
      "metadata": {
        "id": "7Mv1ZBGtpCkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stations_gdf = gpd.GeoDataFrame(\n",
        "    Existing_stations,\n",
        "    geometry=gpd.points_from_xy(Existing_stations['longitude'], Existing_stations['latitude']),\n",
        "    crs=\"EPSG:4326\"\n",
        ")"
      ],
      "metadata": {
        "id": "EJFw9QHEp2zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter the exisitng stations that fall within the geofence polygon"
      ],
      "metadata": {
        "id": "KKrOyEWpqCs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_stations = stations_gdf[stations_gdf.within(geofence_polygon)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "J0CysHYlqJoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the filtered stations to a CSV file"
      ],
      "metadata": {
        "id": "nksaDWU4qRP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_output_path = '/content/filtered_unique_stations_within_geofence.csv'\n",
        "filtered_stations[['station_name', 'latitude', 'longitude']].to_csv(filtered_output_path, index=False)"
      ],
      "metadata": {
        "id": "a6vs48-cqR9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "save the filtered coordinates data"
      ],
      "metadata": {
        "id": "YsD8F8ljqeyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_file_path = '/content/filtered_coordinates_within_geofence.csv'\n",
        "coordinates_df = pd.read_csv(filtered_file_path)"
      ],
      "metadata": {
        "id": "V52ThUF6qfZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define grid size (in degrees, approx. ~100 meters)"
      ],
      "metadata": {
        "id": "Wb7H6WFhqlv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_size = 0.001  # About 100 meters (0.001 degrees)"
      ],
      "metadata": {
        "id": "enStb1RFqoRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate grid cell indices (longitude and latitude)"
      ],
      "metadata": {
        "id": "aP76xhwWqtlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates_df['x_cell'] = (coordinates_df['longitude'] // grid_size).astype(int)\n",
        "coordinates_df['y_cell'] = (coordinates_df['latitude'] // grid_size).astype(int)"
      ],
      "metadata": {
        "id": "5e4dbmwIqtNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group by grid cell and compute centroid and density"
      ],
      "metadata": {
        "id": "0pPrAE68qwrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_summary = coordinates_df.groupby(['x_cell', 'y_cell']).agg(\n",
        "    x=('longitude', 'mean'),\n",
        "    y=('latitude', 'mean'),\n",
        "    density=('latitude', 'size')\n",
        ").reset_index()\n"
      ],
      "metadata": {
        "id": "9VGTavILqzPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the clustered data to a CSV file"
      ],
      "metadata": {
        "id": "EyUNxzJdq1x6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/grid_clustered_coordinates.csv'\n",
        "cluster_summary[['x', 'y', 'density']].to_csv(output_path, index=False)"
      ],
      "metadata": {
        "id": "7wyapn8Jq4VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the clustered coordinates and unique stations data"
      ],
      "metadata": {
        "id": "BwnSBlz-rEGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_file_path = '/content/grid_clustered_coordinates.csv'\n",
        "stations_file_path = '/content/Existing_stations.csv'\n",
        "clusters_df = pd.read_csv(clustered_file_path)\n",
        "stations_df = pd.read_csv(stations_file_path)"
      ],
      "metadata": {
        "id": "LtRvLvAzrEvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rank the clusters by density in descending order"
      ],
      "metadata": {
        "id": "BRET8QFcrQW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clusters_df = clusters_df.sort_values(by='density', ascending=False).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "BULq2tPkrTYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to check if a cluster is within a 200-meter radius of any station"
      ],
      "metadata": {
        "id": "wMdbX1vgrYlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_within_radius(cluster_point, stations, radius=200):\n",
        "    cluster_coords = (cluster_point['y'], cluster_point['x'])\n",
        "    for _, station in stations.iterrows():\n",
        "        station_coords = (station['latitude'], station['longitude'])\n",
        "        if geodesic(cluster_coords, station_coords).meters <= radius:\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "stVkxYCurbNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify the top 5 high-density clusters without a nearby station"
      ],
      "metadata": {
        "id": "ekw6g1XErg3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unserved_clusters = []\n",
        "for _, cluster in clusters_df.iterrows():\n",
        "    if not is_within_radius(cluster, stations_df):\n",
        "        unserved_clusters.append(cluster)\n",
        "    if len(unserved_clusters) >= 5:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "NuQ7H2gFrhpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and save a DataFrame for the top 5 unserved clusters"
      ],
      "metadata": {
        "id": "qPiivSMMrsFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unserved_clusters_df = pd.DataFrame(unserved_clusters)\n",
        "\n",
        "output_path = '/content/top_5_unserved_clusters.csv'\n",
        "unserved_clusters_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Top 5 unserved clusters saved to {output_path}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHd516aJrub6",
        "outputId": "b2e65db8-e50d-4459-e16b-4d1756d3dc49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 unserved clusters saved to /content/top_5_unserved_clusters.csv.\n"
          ]
        }
      ]
    }
  ]
}